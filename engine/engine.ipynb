{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.engine import *\n",
    "from modules.log_reader import read_qsym_log\n",
    "import logging\n",
    "import pandas as pd\n",
    "from dataclasses import asdict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = read_qsym_log(\"./quicksort_medium_export.log\")\n",
    "print(\"Largest query length:\", max(len(q.constraints) for q in queries))\n",
    "len(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_assumption_assertion = False\n",
    "if perform_assumption_assertion:\n",
    "    for i in tqdm(range(len(queries))):\n",
    "        for j in range(i + 1, len(queries)):\n",
    "            first = queries[i]\n",
    "            second = queries[j]\n",
    "            if first.dependencies != second.dependencies:\n",
    "                continue\n",
    "\n",
    "            shorter = first if len(first.path) < len(second.path) else second\n",
    "            longer = first if shorter is second else second\n",
    "            if shorter.path != longer.path[:len(shorter.path)]:\n",
    "                continue\n",
    "\n",
    "            assert shorter.constraints == longer.constraints[:len(shorter.constraints)], f\"{shorter}, {longer}\"\n",
    "    \n",
    "    print(\"Assumption of same prefices generate same constraints holds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategies\n",
    "Solver selection strategy  is the component that determines how solvers are used or generated for queries.\n",
    "\n",
    "#### Basic\n",
    "Generates a new solver for each dependency set and doesn't upgrade it. So it is always an empty solver.\n",
    "\n",
    "##### Rationale\n",
    "Works as a base case (with the benefit of dependency sets).\n",
    "\n",
    "#### Negation\n",
    "Generates a new solver for each branch negation. By negation we mean the negation of the last constraint that symbolic/concolic execution engines check to make a diverging test case.\n",
    "\n",
    "##### Rationale\n",
    "The longer queries of the current program execution, as well as those generated by the new diverging one with share a common prefix.\n",
    "\n",
    "#### Exact Path\n",
    "Almost for each query, generates a new solver. \n",
    "\n",
    "##### Rationale\n",
    "Only useful when there are lots of exactly repeated queries. Also, can be used to measure the repeated query count and the sanity of concolic executions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NegationSolverSelectionStrategy(SolverSelectionStrategy):\n",
    "    def __init__(self, use_copy=False, log_level=logging.DEBUG) -> None:\n",
    "        super().__init__(log_level=log_level)\n",
    "        self.use_copy = use_copy\n",
    "        self.exact_strategy = ExactPathSolverSelectionStrategy(use_copy, log_level)\n",
    "\n",
    "    def get_solver(self, found_solver: MySolver | None, query: Query) -> MySolver:\n",
    "        self._log(\"Found solver for query with id = %d: %s\", query.id, found_solver)\n",
    "\n",
    "        if query.path[-1][1] == BranchAction.OPTIMISTIC:\n",
    "            return self.exact_strategy.get_solver(found_solver, query)\n",
    "\n",
    "        if found_solver is None:\n",
    "            self._log(\"No solver available, Creating a new one\")\n",
    "            solver = self.create_empty_solver()\n",
    "            solver.upgrade(query.path[:-1], query.constraints[:-1])\n",
    "            self._log(solver)\n",
    "            return solver\n",
    "\n",
    "        solver = found_solver\n",
    "        if found_solver.stack_path_len < len(query.path) - 1:\n",
    "            self._log(\"Creating a new solver for a longer path\")\n",
    "            solver = self.create_empty_solver()\n",
    "            if self.use_copy:\n",
    "                solver.copy_from(found_solver)\n",
    "                solver.upgrade(query.path[solver.stack_path_len:-1],\n",
    "                               query.constraints[solver.constraint_count:-1])\n",
    "            else:\n",
    "                solver.upgrade(query.path[:-1], query.constraints[:-1])\n",
    "        else:\n",
    "            self._log(\"Solver is appropriate\")\n",
    "        \n",
    "        self._log(solver)\n",
    "        return solver\n",
    "\n",
    "    def __setattr__(self, __name: str, __value):\n",
    "        if __name == \"create_empty_solver\":\n",
    "            self.exact_strategy.__setattr__(__name, __value)\n",
    "        return super().__setattr__(__name, __value)\n",
    "\n",
    "class ExactPathSolverSelectionStrategy(SolverSelectionStrategy):\n",
    "    def __init__(self, use_copy=False, log_level=logging.DEBUG) -> None:\n",
    "        super().__init__(log_level=log_level)\n",
    "        self.use_copy = use_copy\n",
    "\n",
    "    def get_solver(self, found_solver: MySolver | None, query: Query) -> MySolver:\n",
    "        if found_solver is None:\n",
    "            self._log(\"No solver available, Creating a new one\")\n",
    "            solver = self.create_empty_solver()\n",
    "            solver.upgrade(query.path, query.constraints)\n",
    "            return solver\n",
    "\n",
    "        solver = found_solver\n",
    "        if found_solver.stack_path_len < len(query.path):\n",
    "            self._log(\"Creating a new solver for a longer path\")\n",
    "            solver = self.create_empty_solver()\n",
    "            if self.use_copy:\n",
    "                solver.copy_from(found_solver)\n",
    "                solver.upgrade(query.path[solver.stack_path_len:],\n",
    "                               query.constraints[solver.constraint_count:])\n",
    "            else:\n",
    "                solver.upgrade(query.path, query.constraints)\n",
    "        else:\n",
    "            self._log(\"Solver is appropriate\")\n",
    "        \n",
    "        return solver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategies correctness\n",
    "perform_strategy_assertions = False\n",
    "\n",
    "logging.getLogger().setLevel(level=logging.INFO)\n",
    "\n",
    "if perform_strategy_assertions:\n",
    "    target_queries = queries[:300]\n",
    "    pool = SolverPool()\n",
    "    pool.selection_strategy = BasicSolverSelectionStrategy()\n",
    "    base_results = tuple(pool.solve(q) for q in tqdm(target_queries))\n",
    "\n",
    "    strategies = [\n",
    "        NegationSolverSelectionStrategy(False),\n",
    "        NegationSolverSelectionStrategy(True),\n",
    "        ExactPathSolverSelectionStrategy(),\n",
    "    ]\n",
    "    for strategy in strategies:\n",
    "        name = type(strategy).__name__\n",
    "        logging.info(\"Asserting %s\", name)\n",
    "        pool = SolverPool()\n",
    "        pool.selection_strategy = strategy\n",
    "        pool.enable_solve_prefix_assertions()\n",
    "        for i, q in enumerate(tqdm(target_queries)):\n",
    "            result = pool.solve(q)\n",
    "            assert result == base_results[i], f\"Different result found for the {i}th query, in {name} strategy.\\nDetails:\\nQuery: {q.to_json_serializable()},\\nStrategy Result: {result}, Base Result: {base_results[i]}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = SolverPool(max_solvers=1000)\n",
    "# pool.selection_strategy = BasicSolverSelectionStrategy()\n",
    "pool.selection_strategy = NegationSolverSelectionStrategy()\n",
    "# pool.selection_strategy = ExactPathSolverSelectionStrategy()\n",
    "\n",
    "logging.getLogger().setLevel(level=logging.WARN)\n",
    "\n",
    "for q in queries[:1000]:\n",
    "    pool.solve(q)\n",
    "\n",
    "logging.getLogger().setLevel(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_times_column(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df.drop(columns=[\"times\"], inplace=False).join(\n",
    "        df.apply(lambda x: pd.Series(x[\"times\"].values(), index=x[\"times\"].keys()), axis=1))\n",
    "\n",
    "def describe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return pd.concat([df.describe(), pd.Series(df.sum()).to_frame(\"sum\").transpose()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Solver tree count:\", len(pool._solver_trees))\n",
    "print(\"Total alive solver count:\", len(pool._solvers.items))\n",
    "print(\"Most recently used solver:\", list(pool._solvers.items.items())[-1][1]._solver)\n",
    "print(\"Solver cache statistics:\", pool._solvers.statistics)\n",
    "solver_data = pd.DataFrame([asdict(stats) for stats in pool.statistics.solvers.values()])\n",
    "solver_data = expand_times_column(solver_data)\n",
    "describe(solver_data)\n",
    "pd.concat([describe(solver_data), describe(solver_data)]).groupby(level=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_data = pd.DataFrame([asdict(stats) for stats in pool.statistics.trees.values()])\n",
    "tree_data = expand_times_column(tree_data)\n",
    "describe(tree_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(queries, strategy, max_solvers=200, repeat_count=5):\n",
    "    with tqdm(total=repeat_count * len(queries)) as pb:\n",
    "        datas = list()\n",
    "        for _ in range(repeat_count):\n",
    "            pool = SolverPool(max_solvers=max_solvers)\n",
    "            pool.selection_strategy = strategy\n",
    "            for q in queries:\n",
    "                pool.solve(q)\n",
    "                pb.update()\n",
    "\n",
    "            solvers_counts = pd.DataFrame(\n",
    "                [stats.times for stats in pool.statistics.solvers.values()])\n",
    "\n",
    "            trees_stats = pd.DataFrame(\n",
    "                [stats.times for stats in pool.statistics.trees.values()])\n",
    "\n",
    "            datas.append((describe(solvers_counts), describe(trees_stats)))\n",
    "\n",
    "    def average(datas):\n",
    "        return pd.concat(datas).groupby(level=0).mean().transpose().drop(columns=[\"count\"], inplace=False)\n",
    "\n",
    "    solvers_times = average([data[0] for data in datas])\n",
    "    trees_times = average([data[1] for data in datas])\n",
    "\n",
    "    # Counting statistics is same for each run.\n",
    "    cache_stats = pool.statistics.cache\n",
    "    solvers_counts = pd.DataFrame([asdict(stats) for stats in pool.statistics.solvers.values()])\\\n",
    "        .drop(columns=[\"times\"], inplace=False)\n",
    "    solvers_counts = describe(solvers_counts)\n",
    "\n",
    "    del pool\n",
    "    return {\n",
    "        \"cache\": cache_stats,\n",
    "        \"solvers_counts\": solvers_counts,\n",
    "        \"solvers_times\": solvers_times,\n",
    "        \"trees_times\": trees_times,\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_and_save(name, queries, strategy, max_solvers=200, repeat_count=5):\n",
    "    result = evaluate(queries, strategy, max_solvers, repeat_count)\n",
    "    to_write = {\n",
    "        \"cache\": asdict(result[\"cache\"]),\n",
    "        \"solvers_counts\": result[\"solvers_counts\"].to_dict(),\n",
    "        \"solvers_times\": result[\"solvers_times\"].to_dict(),\n",
    "        \"trees_times\": result[\"trees_times\"].to_dict(),\n",
    "    }\n",
    "\n",
    "    from pathlib import Path\n",
    "    Path(f\"./evaluations\").mkdir(exist_ok=True)\n",
    "    with open(f\"./evaluations/{name}.json\", \"w\") as f:\n",
    "        import json\n",
    "        json.dump(to_write, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_and_save(\"negnocopy__quicksort_medium__400\", queries[:100], NegationSolverSelectionStrategy(), max_solvers=400, repeat_count=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('st_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f882a3639542dd5811c1790480d5caf019b9e40a56d63205866f35f84192d7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
