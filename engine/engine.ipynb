{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.engine import *\n",
    "from modules.log_reader import read_qsym_log\n",
    "import logging\n",
    "import pandas as pd\n",
    "from dataclasses import asdict\n",
    "from tqdm import tqdm\n",
    "from abc import abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_assumption_assertion = False\n",
    "if perform_assumption_assertion:\n",
    "    for i in tqdm(range(len(queries))):\n",
    "        for j in range(i + 1, len(queries)):\n",
    "            first = queries[i]\n",
    "            second = queries[j]\n",
    "            if first.dependencies != second.dependencies:\n",
    "                continue\n",
    "\n",
    "            shorter = first if len(first.path) < len(second.path) else second\n",
    "            longer = first if shorter is second else second\n",
    "            if shorter.path != longer.path[:len(shorter.path)]:\n",
    "                continue\n",
    "\n",
    "            assert shorter.constraints == longer.constraints[:len(shorter.constraints)], f\"{shorter}, {longer}\"\n",
    "    \n",
    "    print(\"Assumption of same prefices generate same constraints holds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategies\n",
    "Solver selection strategy  is the component that determines how solvers are used or generated for queries.\n",
    "\n",
    "#### Basic\n",
    "Generates a new solver for each dependency set and doesn't upgrade it. So it is always an empty solver.\n",
    "\n",
    "##### Rationale\n",
    "Works as a base case (with the benefit of dependency sets).\n",
    "\n",
    "#### Negation\n",
    "Generates a new solver for each branch negation. By negation we mean the negation of the last constraint that symbolic/concolic execution engines check to make a diverging test case.\n",
    "\n",
    "##### Rationale\n",
    "The longer queries of the current program execution, as well as those generated by the new diverging one with share a common prefix.\n",
    "\n",
    "#### Exact Path\n",
    "Almost for each query, generates a new solver. \n",
    "\n",
    "##### Rationale\n",
    "Only useful when there are lots of exactly repeated queries. Also, can be used to measure the repeated query count and the sanity of concolic executions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LengthSolverSelectionStrategy(SolverSelectionStrategy):\n",
    "    def __init__(self, log_level=logging.DEBUG, use_copy=False, use_exact_for_optimistic=True):\n",
    "        super().__init__(log_level=log_level)\n",
    "        self.use_copy = use_copy\n",
    "        if use_exact_for_optimistic:\n",
    "            self.exact_strategy = ExactPathSolverSelectionStrategy(\n",
    "                use_copy, log_level)\n",
    "\n",
    "    def _create_solver(self, path, constraints, existing_solver: MySolver = None):\n",
    "        return super()._create_solver(path, constraints, existing_solver, self.use_copy)\n",
    "\n",
    "    def get_solver(self, found_solver: MySolver | None, query: Query) -> MySolver:\n",
    "        # if query.path[-1][1] == BranchAction.OPTIMISTIC and hasattr(self, \"exact_strategy\"):\n",
    "        #     self.exact_strategy.get_solver(found_solver, query)\n",
    "        if query.path[-1][1] == BranchAction.OPTIMISTIC:\n",
    "            if found_solver is None:\n",
    "                return self.create_empty_solver()\n",
    "            return found_solver\n",
    "\n",
    "        if found_solver is None:\n",
    "            path, constraints = self._get_upgrade_parts(query)\n",
    "            solver = self._create_solver(path, constraints)\n",
    "            self._log(\"No solver available for query with id = %d, created a new one: %s\", query.id, solver)\n",
    "            return solver\n",
    "\n",
    "        self._log(\"Found solver for query with id = %d: %s\",\n",
    "                  query.id, found_solver)\n",
    "        solver = found_solver\n",
    "        if not self._is_appropriate(found_solver, query):\n",
    "            self._log(\"Creating a new solver for a longer path\")\n",
    "            path, constraints = self._get_upgrade_parts(query)\n",
    "            solver = self._create_solver(path, constraints, found_solver)\n",
    "        else:\n",
    "            self._log(\"Solver is appropriate\")\n",
    "\n",
    "        return solver\n",
    "\n",
    "    @abstractmethod\n",
    "    def _is_appropriate(self, found_solver: MySolver, query: Query) -> bool:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _get_upgrade_parts(self, query):\n",
    "        pass\n",
    "\n",
    "    def __setattr__(self, __name: str, __value):\n",
    "        if __name == \"create_empty_solver\" and hasattr(self, \"exact_strategy\"):\n",
    "            self.exact_strategy.__setattr__(__name, __value)\n",
    "        return super().__setattr__(__name, __value)\n",
    "\n",
    "\n",
    "class NegationSolverSelectionStrategy(LengthSolverSelectionStrategy):\n",
    "    def _is_appropriate(self, found_solver: MySolver, query: Query) -> bool:\n",
    "        return found_solver.stack_path_len >= len(query.path) - 1\n",
    "\n",
    "    def _get_upgrade_parts(self, query):\n",
    "        return query.path[:-1], query.constraints[:-1]\n",
    "\n",
    "\n",
    "class ExactPathSolverSelectionStrategy(LengthSolverSelectionStrategy):\n",
    "    def __init__(self, log_level=logging.DEBUG, use_copy=False, use_exact_for_optimistic=False):\n",
    "        super().__init__(log_level, use_copy, use_exact_for_optimistic)\n",
    "\n",
    "    def _is_appropriate(self, found_solver: MySolver, query: Query) -> bool:\n",
    "        return found_solver.stack_path_len == len(query.path)\n",
    "\n",
    "    def _get_upgrade_parts(self, query):\n",
    "        return query.path, query.constraints\n",
    "\n",
    "\n",
    "class LengthRatioSolverSelectionStrategy(ExactPathSolverSelectionStrategy):\n",
    "    def __init__(self, ratio = 3/4, log_level=logging.DEBUG, use_copy=False, use_exact_for_optimistic=True) -> None:\n",
    "        super().__init__(log_level=log_level, use_copy=use_copy,\n",
    "                         use_exact_for_optimistic=use_exact_for_optimistic)\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def _is_appropriate(self, found_solver: MySolver, query: Query) -> bool:\n",
    "        result = found_solver.stack_path_len >= len(query.path) * self.ratio\n",
    "        if not result:\n",
    "            self._log(\"%d was not enough for %d\", found_solver.stack_path_len, len(query.path))\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategies correctness\n",
    "perform_strategy_assertions = False\n",
    "\n",
    "logging.getLogger().setLevel(level=logging.INFO)\n",
    "\n",
    "if perform_strategy_assertions:\n",
    "    target_queries = queries[:300]\n",
    "    pool = SolverPool()\n",
    "    pool.selection_strategy = BasicSolverSelectionStrategy()\n",
    "    base_results = tuple(pool.solve(q) for q in tqdm(target_queries))\n",
    "\n",
    "    strategies = [\n",
    "        NegationSolverSelectionStrategy(use_copy=False),\n",
    "        NegationSolverSelectionStrategy(use_copy=True),\n",
    "        ExactPathSolverSelectionStrategy(),\n",
    "        LengthRatioSolverSelectionStrategy()\n",
    "    ]\n",
    "    for strategy in strategies:\n",
    "        name = type(strategy).__name__\n",
    "        logging.info(\"Asserting %s\", name)\n",
    "        pool = SolverPool()\n",
    "        pool.selection_strategy = strategy\n",
    "        pool.enable_solve_prefix_assertions()\n",
    "        for i, q in enumerate(tqdm(target_queries)):\n",
    "            result = pool.solve(q)\n",
    "            assert result == base_results[i], f\"Different result found for the {i}th query, in {name} strategy.\\nDetails:\\nQuery: {q.to_json_serializable()},\\nStrategy Result: {result}, Base Result: {base_results[i]}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_times_column(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df.drop(columns=[\"times\"], inplace=False).join(\n",
    "        df.apply(lambda x: pd.Series(x[\"times\"].values(), index=x[\"times\"].keys()), axis=1))\n",
    "\n",
    "def describe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return pd.concat([df.describe(), pd.Series(df.sum()).to_frame(\"sum\").transpose()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(queries, strategy, max_solvers=200, repeat_count=5):\n",
    "    with tqdm(total=repeat_count * len(queries)) as pb:\n",
    "        datas = list()\n",
    "        for _ in range(repeat_count):\n",
    "            pool = SolverPool(max_solvers=max_solvers)\n",
    "            pool.selection_strategy = strategy\n",
    "            for q in queries:\n",
    "                pool.solve(q)\n",
    "                pb.update()\n",
    "\n",
    "            solvers_counts = pd.DataFrame(\n",
    "                [stats.times for stats in pool.statistics.solvers.values()])\n",
    "\n",
    "            trees_stats = pd.DataFrame(\n",
    "                [stats.times for stats in pool.statistics.trees.values()])\n",
    "\n",
    "            datas.append((describe(solvers_counts), describe(trees_stats)))\n",
    "\n",
    "    def average(datas):\n",
    "        return pd.concat(datas).groupby(level=0).mean().transpose().drop(columns=[\"count\"], inplace=False)\n",
    "\n",
    "    solvers_times = average([data[0] for data in datas])\n",
    "    trees_times = average([data[1] for data in datas])\n",
    "\n",
    "    # Counting statistics is same for each run.\n",
    "    cache_stats = pool.statistics.cache\n",
    "    solvers_counts = pd.DataFrame([asdict(stats) for stats in pool.statistics.solvers.values()])\\\n",
    "        .drop(columns=[\"times\"], inplace=False)\n",
    "    solvers_counts = describe(solvers_counts).transpose()\n",
    "\n",
    "    del pool\n",
    "    return {\n",
    "        \"cache\": cache_stats,\n",
    "        \"solvers_counts\": solvers_counts,\n",
    "        \"solvers_times\": solvers_times,\n",
    "        \"trees_times\": trees_times,\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_and_save(name, queries, strategy, max_solvers=200, repeat_count=5):\n",
    "    result = evaluate(queries, strategy, max_solvers, repeat_count)\n",
    "    to_write = {\n",
    "        \"cache\": asdict(result[\"cache\"]),\n",
    "        \"solvers_counts\": result[\"solvers_counts\"].to_dict(),\n",
    "        \"solvers_times\": result[\"solvers_times\"].to_dict(),\n",
    "        \"trees_times\": result[\"trees_times\"].to_dict(),\n",
    "    }\n",
    "\n",
    "    from pathlib import Path\n",
    "    Path(f\"./evaluations\").mkdir(exist_ok=True)\n",
    "    with open(f\"./evaluations/{name}.json\", \"w\") as f:\n",
    "        import json\n",
    "        json.dump(to_write, f)\n",
    "\n",
    "    logging.info(\"Wrote evaluation result to %s.json\", name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repeated_queries(queries):\n",
    "    counter = 0\n",
    "    with tqdm(total=(len(queries) + 1)* len(queries) // 2) as pb:\n",
    "        for i in tqdm(range(len(queries))):\n",
    "            for j in range(i + 1, len(queries)):\n",
    "                pb.update()\n",
    "                \n",
    "                first = queries[i]\n",
    "                second = queries[j]\n",
    "                if first is None or second is None:\n",
    "                    continue\n",
    "                if (first.dependencies == second.dependencies\n",
    "                    and first.path == second.path\n",
    "                        and first.constraints == second.constraints):\n",
    "                    counter += 1\n",
    "                    queries[j] = None\n",
    "    logging.info(\"Removed %d repeated queries from %d\", counter, len(queries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_files = [\n",
    "    # \"quicksort_medium_export.log\",\n",
    "    # \"The_longest_Road.log\",\n",
    "    \"pattern_finder.log\",\n",
    "]\n",
    "strategies = {\n",
    "    \"basic\": BasicSolverSelectionStrategy(),\n",
    "    \"negnocopy\": NegationSolverSelectionStrategy(use_copy=False),\n",
    "    \"negcopy\": NegationSolverSelectionStrategy(use_copy=True),\n",
    "    \"exactnocopy\": ExactPathSolverSelectionStrategy(use_copy=False),\n",
    "    \"ratio3_4nocopy\": LengthRatioSolverSelectionStrategy(3/4, use_copy=False),\n",
    "    \"ratio1_2nocopy\": LengthRatioSolverSelectionStrategy(1/2, use_copy=False),\n",
    "}\n",
    "\n",
    "def evaluate_for_strategy_max_solvers(strategy_name, max_solvers):\n",
    "    global eval_queries\n",
    "    name = f\"{strategy_name}__{log_file}_{len(eval_queries)}__{max_solvers}\"\n",
    "    logging.info(\"Evaluating: %s\", name)\n",
    "    evaluate_and_save(\n",
    "        name,\n",
    "        eval_queries,\n",
    "        strategies[strategy_name],\n",
    "        max_solvers=max_solvers,\n",
    "        repeat_count=2)\n",
    "        \n",
    "\n",
    "max_solvers_sizes = [200, 400, 1000]\n",
    "for log_file in log_files:\n",
    "    global eval_queries\n",
    "    logging.info(\"Reading the log file: %s\", log_file)\n",
    "    eval_queries = read_qsym_log(log_file)[:5000]\n",
    "    logging.info(\"Removing repeated queries\")\n",
    "    remove_repeated_queries(eval_queries)\n",
    "\n",
    "    from multiprocessing import Pool\n",
    "    with Pool() as p:\n",
    "        p.starmap(evaluate_for_strategy_max_solvers, [(strategy, max_solvers) for strategy in strategies.keys() for max_solvers in max_solvers_sizes])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('st_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f882a3639542dd5811c1790480d5caf019b9e40a56d63205866f35f84192d7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
