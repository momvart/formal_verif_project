{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from z3 import *\n",
    "import z3\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_queries_from_klee_smt2_dump(path: str):\n",
    "    queries = []\n",
    "    with open(path) as f:\n",
    "        current = \"\"\n",
    "        for line in f:\n",
    "            if line == \"(check-sat)\":\n",
    "                continue\n",
    "            if line.strip() == \"(reset)\":\n",
    "                queries.append(z3.parse_smt2_string(current))\n",
    "                current = \"\"\n",
    "            current += line\n",
    "    return queries        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4302 queries were loaded.\n"
     ]
    }
   ],
   "source": [
    "queries = parse_queries_from_klee_smt2_dump(\"echo-cache.smt2\")\n",
    "print(f\"{len(queries)} queries were loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distance_keeping_constraint_order(first: list, second: list, pop_cost, push_cost):\n",
    "    \"\"\"\n",
    "    Calculates a distance between two queries while not trying to change the order\n",
    "    of constraints inside them.\n",
    "    The returned distance mimics the cost of pushing and popping when the second query\n",
    "    is solved right after the first query.\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    while i < len(first) and i < len(second) and first[i].eq(second[i]):\n",
    "        i += 1\n",
    "\n",
    "    return (i, pop_cost(len(first) - i) + push_cost(len(second) - i))\n",
    "    # If you believe that there's no cost in popping, you can use the following\n",
    "    # formula. But personally, I see each pop as a negative thing and losing a\n",
    "    # progress.\n",
    "    # return (i, len(second) - i)\n",
    "\n",
    "def calc_distances_for(query_index: int, queries, calc_distance, pop_cost, push_cost):\n",
    "    query = queries[query_index]\n",
    "    distances = [0] * len(queries)\n",
    "    for j in range(len(queries)):\n",
    "        distances[j] = calc_distance(query, queries[j], pop_cost, push_cost)\n",
    "    return distances\n",
    "\n",
    "pop_cost = lambda x: x\n",
    "push_cost = lambda x: x\n",
    "\n",
    "def calc_distances_for_map(query_index: int):\n",
    "    return calc_distances_for(query_index, queries, calc_distance_keeping_constraint_order, pop_cost, push_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4302/4302 [00:28<00:00, 149.23it/s]\n"
     ]
    }
   ],
   "source": [
    "with ProcessPoolExecutor() as executor:\n",
    "    distances = list(tqdm(executor.map(calc_distances_for_map, range(len(queries))), total=len(queries)))\n",
    "\n",
    "common_prefix_lens = [[col[0] for col in row] for row in distances]\n",
    "distances = [[col[1] for col in row] for row in distances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tsp_circuit(distances):\n",
    "    import ortools.constraint_solver.pywrapcp as pywrapcp\n",
    "    from ortools.constraint_solver import routing_enums_pb2\n",
    "\n",
    "    manager = pywrapcp.RoutingIndexManager(len(distances), 1, 0)\n",
    "    routing = pywrapcp.RoutingModel(manager)\n",
    "\n",
    "    def distance_callback(from_index, to_index):\n",
    "        \"\"\"Returns the distance between the two nodes.\"\"\"\n",
    "        # Convert from routing variable Index to distance matrix NodeIndex.\n",
    "        from_node = manager.IndexToNode(from_index)\n",
    "        to_node = manager.IndexToNode(to_index)\n",
    "        return distances[from_node][to_node]\n",
    "\n",
    "    transit_callback_index = routing.RegisterTransitCallback(distance_callback)\n",
    "    routing.SetArcCostEvaluatorOfAllVehicles(transit_callback_index)\n",
    "    search_parameters = pywrapcp.DefaultRoutingSearchParameters()\n",
    "    search_parameters.first_solution_strategy = (\n",
    "        routing_enums_pb2.FirstSolutionStrategy.AUTOMATIC)\n",
    "\n",
    "    def print_solution(manager, routing, solution):\n",
    "        \"\"\"Prints solution on console.\"\"\"\n",
    "        print('Objective: {} miles'.format(solution.ObjectiveValue()))\n",
    "        index = routing.Start(0)\n",
    "        plan_output = 'Route for vehicle 0:\\n'\n",
    "        route_distance = 0\n",
    "        while not routing.IsEnd(index):\n",
    "            plan_output += ' {} ->'.format(manager.IndexToNode(index))\n",
    "            previous_index = index\n",
    "            index = solution.Value(routing.NextVar(index))\n",
    "            route_distance += routing.GetArcCostForVehicle(previous_index, index, 0)\n",
    "        plan_output += ' {}\\n'.format(manager.IndexToNode(index))\n",
    "        print(plan_output)\n",
    "        plan_output += 'Route distance: {}miles\\n'.format(route_distance)\n",
    "\n",
    "    def get_vector(manager, routing, solution):\n",
    "        index = routing.Start(0)\n",
    "        route = []\n",
    "        while not routing.IsEnd(index):\n",
    "            route.append(manager.IndexToNode(index))\n",
    "            index = solution.Value(routing.NextVar(index))\n",
    "\n",
    "        return route\n",
    "\n",
    "    solution = routing.SolveWithParameters(search_parameters)\n",
    "    # if solution:\n",
    "    #     print_solution(manager, routing, solution)\n",
    "\n",
    "    return get_vector(manager, routing, solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_case = get_tsp_circuit(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def check_by_resetting(queries, ordering: List[int], common_prefix_lens, enable_direct_subset_answer=False, solver=None):\n",
    "    solver = solver if solver is not None else Solver()\n",
    "    results = {}\n",
    "    \n",
    "    total_time = 0.0\n",
    "    \n",
    "    for index in tqdm(ordering):\n",
    "        query = queries[index]\n",
    "        start_time = time.perf_counter()\n",
    "        result = solver.check(query)\n",
    "        end_time = time.perf_counter()\n",
    "        total_time += end_time - start_time\n",
    "        results[index] = result\n",
    "    \n",
    "    return (results, solver.statistics(), total_time, (0, 0, 0))\n",
    "\n",
    "def check_dummy_incrementally(queries, ordering: List[int], common_prefix_lens, enable_direct_subset_answer=False, solver=None):\n",
    "    solver = solver if solver is not None else Solver()\n",
    "    results = {}\n",
    "\n",
    "    last_query = []\n",
    "\n",
    "    total_time = 0.0\n",
    "    total_pops = 0\n",
    "    total_pushes = 0\n",
    "\n",
    "    for index in tqdm(ordering):\n",
    "        if index in results:\n",
    "            print(\"Warning: Skipping repeated query. Query index =\", index)\n",
    "            continue\n",
    "        query = queries[index]\n",
    "        \n",
    "        i = 0\n",
    "        while i < len(last_query) and i < len(query) and last_query[i].eq(query[i]):\n",
    "            i += 1\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "        \n",
    "        solver.pop(len(last_query) - i)\n",
    "        total_pops += len(last_query) - i\n",
    "\n",
    "        for i in range(i, len(query)):\n",
    "            solver.push()\n",
    "            total_pushes += 1\n",
    "            solver.add(query[i])\n",
    "        \n",
    "        result = solver.check()\n",
    "        end_time = time.perf_counter()\n",
    "        total_time += end_time - start_time\n",
    "        results[index] = result\n",
    "\n",
    "        last_query = query\n",
    "    \n",
    "    return (results, solver.statistics(), total_time, (total_pushes, total_pops, sum(len(q) for q in queries)))\n",
    "\n",
    "def check_incrementally(queries, ordering: List[int], common_prefix_lens, enable_direct_subset_answer=False, solver=None):\n",
    "    solver = solver if solver is not None else Solver()\n",
    "    results = {}\n",
    "\n",
    "    queries = queries + [queries[ordering[-1]]]\n",
    "    ordering = ordering + [ordering[-1]]\n",
    "    \n",
    "    last_index = len(queries) - 1\n",
    "    current_stack_count = 0\n",
    "\n",
    "    total_time = 0.0\n",
    "    total_pops = 0\n",
    "    total_pushes = 0\n",
    "\n",
    "    for index, next_index in tqdm(zip(ordering[:len(ordering) - 1], ordering[1:]), total=len(queries) - 1):\n",
    "        if index in results:\n",
    "            print(\"Warning: Skipping repeated query. Query index =\", index)\n",
    "            continue\n",
    "        # last_query = queries[last_index]\n",
    "        query = queries[index]\n",
    "        \n",
    "        next_prefix_len = common_prefix_lens[index][next_index]\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "        if enable_direct_subset_answer and current_stack_count == len(query) and results[last_index] == sat:\n",
    "            results[index] = sat\n",
    "        else:\n",
    "            if current_stack_count < next_prefix_len:\n",
    "                for i in range(current_stack_count, next_prefix_len):\n",
    "                    solver.push()\n",
    "                    solver.add(query[i])\n",
    "                total_pushes += next_prefix_len - current_stack_count\n",
    "                current_stack_count = next_prefix_len\n",
    "\n",
    "            solver.push()\n",
    "            total_pushes += 1\n",
    "            solver.add(query[current_stack_count:])\n",
    "            \n",
    "            result = solver.check()\n",
    "\n",
    "            solver.pop()\n",
    "            total_pops +=1\n",
    "                        \n",
    "            results[index] = result\n",
    "        \n",
    "        if current_stack_count > next_prefix_len:\n",
    "            solver.pop(current_stack_count - next_prefix_len)\n",
    "            total_pops += current_stack_count - next_prefix_len\n",
    "            current_stack_count = next_prefix_len\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "        total_time += end_time - start_time\n",
    "        last_index = index\n",
    "    \n",
    "    return (results, solver.statistics(), total_time, (total_pushes, total_pops, sum(len(q) for q in queries)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4302/4302 [00:14<00:00, 292.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent time: 14.654909132630564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Base case\n",
    "base_results, statistics, total_time, _ = check_by_resetting(queries, list(range(len(queries))), common_prefix_lens)\n",
    "print(\"Spent time:\", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4302/4302 [00:15<00:00, 282.27it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.20084131823387\n",
      "334036 334043 679921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_results, statistics, total_time, (total_pushes, total_pops, total_constraints) = check_dummy_incrementally(queries, list(range(len(queries))), common_prefix_lens)\n",
    "assert(base_results == best_results)\n",
    "print(total_time)\n",
    "print(total_pops, total_pushes, total_constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4302/4302 [00:08<00:00, 481.63it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.891306128469296\n",
      "149101 149108 679928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_results, statistics, total_time, (total_pushes, total_pops, total_constraints) = check_incrementally(queries, list(range(len(queries))), common_prefix_lens)\n",
    "assert(base_results == best_results)\n",
    "print(total_time)\n",
    "print(total_pops, total_pushes, total_constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4302/4302 [00:08<00:00, 492.59it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.698012300301343\n",
      "148177 148458 680202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Best case\n",
    "best_results, statistics, total_time, (total_pushes, total_pops, total_constraints) = check_incrementally(queries, best_case, common_prefix_lens, True)\n",
    "assert(base_results == best_results)\n",
    "print(total_time)\n",
    "print(total_pops, total_pushes, total_constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_distances():\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        distances = list(tqdm(executor.map(calc_distances_for_map, range(len(queries))), total=len(queries)))\n",
    "\n",
    "    common_prefix_lens = [[col[0] for col in row] for row in distances]\n",
    "    distances = [[col[1] for col in row] for row in distances]\n",
    "    return common_prefix_lens, distances\n",
    "\n",
    "def evaluate(name, enable_direct_subset_answer, output_suffix, repeat_count = 5, input_suffix = \".smt2\"):\n",
    "    # Using global because of pickling\n",
    "    global queries\n",
    "    queries = parse_queries_from_klee_smt2_dump(name + input_suffix)\n",
    "    print(f\"Evaluating {name} with {len(queries)} queries.\")\n",
    "\n",
    "    print(\"Calculating distances ...\")\n",
    "    common_prefix_lens, distances = calc_distances()\n",
    "    \n",
    "    original_ordering = list(range(len(queries)))\n",
    "    print(\"Finding TSP ordering ...\")\n",
    "    tsp_ordering = get_tsp_circuit(distances)\n",
    "    \n",
    "    cases = {\n",
    "        \"res_original\": (check_by_resetting, original_ordering),\n",
    "        \"dinc_original\": (check_dummy_incrementally, original_ordering),\n",
    "        \"incr_original\": (check_incrementally, original_ordering),\n",
    "        \"incr_tsp\": (check_incrementally, tsp_ordering)\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    check_results = []\n",
    "    for (key, (check, ordering)) in cases.items():\n",
    "        print(f\"Testing {key} for {repeat_count} times ...\")\n",
    "\n",
    "        times = []\n",
    "        for i in range(repeat_count):\n",
    "            check_result, statistics, total_time, (total_pushes, total_pops, total_constraints) = check(queries, ordering, common_prefix_lens, enable_direct_subset_answer)\n",
    "            times.append(total_time)\n",
    "        check_results.append(check_result)\n",
    "        print(total_time)\n",
    "        \n",
    "        results[key] = {\n",
    "            \"times\": times,\n",
    "            \"statistics\": str(statistics),\n",
    "            \"check_result\": {key: str(value) for key, value in check_results[-1].items()},\n",
    "            \"ordering\": ordering,\n",
    "            \"total_pushes\": total_pushes,\n",
    "            \"total_pops\": total_pops,\n",
    "            \"total_constraints\": total_constraints,\n",
    "        }\n",
    "    \n",
    "    assert all(result == check_results[0] for result in check_results)\n",
    "    \n",
    "    import json\n",
    "    file_name = f\"{name}_{output_suffix}\"\n",
    "    while os.path.exists(f\"{file_name}.json\"):\n",
    "        file_name += \"_new\"\n",
    "    with open(f\"{file_name}.json\", \"a\") as f:\n",
    "        json.dump(results, f)\n",
    "\n",
    "    print(\"Result saved to:\", file_name)\n",
    "\n",
    "def zero_cost(x):\n",
    "    return 0\n",
    "\n",
    "def identity_cost(x):\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating echo-cache with 4302 queries.\n",
      "Calculating distances ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4302/4302 [00:28<00:00, 151.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding TSP ordering ...\n"
     ]
    }
   ],
   "source": [
    "push_cost = identity_cost\n",
    "pop_cost = zero_cost\n",
    "evaluate(\"echo-cache\", True, \"direct_i_0\")\n",
    "evaluate(\"echo-nocache\", True, \"direct_i_0\")\n",
    "evaluate(\"pwd-nocache\", True, \"direct_i_0\")\n",
    "evaluate(\"tail-cache\", True, \"direct_i_0\")\n",
    "evaluate(\"tail-nocache\", True, \"direct_i_0\")\n",
    "evaluate(\"who-cache\", True, \"direct_i_0\")\n",
    "evaluate(\"who-nocache\", True, \"direct_i_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('st_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f882a3639542dd5811c1790480d5caf019b9e40a56d63205866f35f84192d7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
